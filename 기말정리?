인공지능 머신러닝 딥러닝 구분 (그림, 영어, 종류 달달), 지도학습, 비지도학습 등등 차이점 label이 없다,  분류와 회귀 (classification, regression) 비지도 학습은 클러스터
머신러닝의 종류 등등 지도학습은 label이 있느냐 없느냐 분류와 회귀 
Knn K 최근접 이웃: 직관적이며 사용하기 쉽니다. 
강화학습은 에이전트랑 환경 agent, environment,act,  reward를 받고 state 상태
알고리즘 svm, mt?, kmeans, knn을 언제 쓰면 안되냐: 데이터가 너무 많을때 대략 수천개이상
svm은 2차원과 3차원을 병행하면서 잘 나눈다. 속도가 빠르다. 마진을 얼마나 할 것이냐가 관건 마진에 걸리는 서포트 벡터만 가지고 계산을 하기 때문에 속도가 빠르다. 3d에서도 충분히 쓸 수 있다.
선형분류와 비선형 분류 3차원일땐 hyper 붙인다.
결정트리 데이터를 분류하는 방식 
혼동행렬 간경화 걸렸는지 안걸렸는지 예시로 tp fn fp tn 예측 및 공식  accuracy(정확도), precision(정밀도), Recall(재현율), (Sensitivity:민감도), F1-Score: 조화평균을 사용 2 * Precision * Recall / Precision + Recall

로지스틱 회귀와 선형회귀 로지스틱  평균제곱법  MSE 그리고 MSE에 제곱을 하는 이유 
비지도 학습은 kmeans와 kmeans++
주성분 분석 (PCA) 차원의 저주가 가능성 차원축소(Dimensionality reduction) 하는 이유는 차원의 저주를 없애기 위해서, 속성이 줄어든다 = 차원이 줄어든다
K 암베도우? 를 쓴다 k값 차트에서 기울기가 급해지는 구간부터 기울기가 완만해지는 2~3번째 값을 다 해 봐야 한다.
밀도기반 군집은 그룹을 하나 잡고 옆에있는거를 또 그룹으로 잡고 2 그룹을 또 묶는다. 군집 확대
overfitting이 뭔지 underfitting이 뭔지 설명 overfitting 연습할 때 잘되는덴 실전에서는 잘 안됨 : 뭐가 문제냐 : 데이터가 문제다. 데이터 증감을 시킨다. gan(생성모델)을 통해서 데이터증감을 시킨다. underfitting은 연습할 때 잘 안되고 실전에서 잘 됨
kmeans 센트로이드를 가야한다. 그룹의 가운데로 움직여서 거리계산 해서 가까운 애들끼리 그룹 잡기 반복 kmeans++ 나오는 이유 센트로이드 문제? k값을 한번에 넣는게 아닌 하나 하나 넣고 가장 먼거리에 있는 애들 잡는다. 
아이리스, 보스턴 집 값, mnist 

relu와 leakyrelu의 차이점 음수로 가는애들을 1이하의 작게 만든다.
출력할때는 cele어쩌구 쓴다. 뭔 그림도 나온다.
퍼셉트론, CNN 코드로 나온다?
accuracy 뽑아 낼 때 confusion matrix (혼동 행렬 쓴다) f1 score, recall, precision 등등 공식
딥러닝 : 이미지 처리를 할 것이냐(CNN), 자연어 처리를 할 것이냐(워드클라우드)
워드클라우드는 코드로 나오고  ** TF-IDF ** 매우 중요 정보검색 스무딩을 하기 위해 1+ 해준다 스무딩의 역활 
전이학습 성능 최적화 : 최대한 많은 데이터 수집하기 모델 선택 ->훈련 -> 하이퍼 파라미터 변경 반복 -> 최적의 성능 도출
활성화 함수 (CNN 28 * 28 hidden(활성화 함수(시그모이드, tanh, relu, leaklyrelu) 을 주고 출력 할때는 소프트 맥스 쓴다(softmax) 손실함수 adam만 사용
앙상블(ensemble)을 이용한 성능 최적한 * 모델을 두 개 이상 섞어서 사용하는 것
드롭아웃과 조기종료 드롭아웃 : hidden이 너무 많아서 backpropagation이 안될 때 hidden을 20% ~ 30% 정도 버리고 간다. 조기종료: epoch가 100번정도에서 잘나오고 200번에서 overfitting이 나면 100번에서 자르는게 조기종료 (별로 좋은 방법은 아님)
정규화(normalization) 0~255 사이 값 
기울기 소멸(gradient vansihing)

자연어 처리: 말뭉치(corpos), 자연어 처리과정 그림 통째로 그리고 그 안의 용어 및 과정 다 외우기
데이터를 가져오면 뭐를 할거냐 확인 할때 describe를 하고 결측치 확인(isnull() 메소드 사용) 결측치가 있을 때 어떻게 할 것이냐 3가지 방법을 쓰라 1번 결측치를 삭제한다, 2번 중간값, 3번 최빈값: 데이터가 적을 때에는 삭제를 하지 않는다.
불용어(stop word) 제거가 반드시 필요함
임베딩(embedding)은 자연어를 컴퓨터가 이해할 수 있는 숫자 형태인 벡터로 변환한 결과나 과정을 의미한다.
TF-IDF(Term Frequency-Inverse Document Frequency)는 정보 검색론(information Retrieval)에서 가중치를 구할 때 사용되는 알고리즘 tf-idf 구하는 표 (기말고사에서는 4개짜리 문장으로 나온다.) 그리고 계산하는거  

생성 모델 오토인코더, 변형오토인코더, 적대적 생성 신경망(GAN) 
생성모델이란 generative model  데이터를 학습하여 데이터의 분포를 따르는 유사한 데이터를 생성하는 모델
판별자 모델 (discriminative model)
판별자 모델을 모델에서 추출한 특성들의 조합을 이용해서 새로운 개와 고양이 이미지를 생성하는것 *생성자모델(generative model)*
생성 모델의 유형중 암시적 방법(GAN), 명시적 방법: 오토인코더
오토인코더는 단순히 입력을 출력으로 복사하는 신경망:  오토인코더의 은닉층(병목층)은 입력과 출력의 뉴런보다 훨씬 작음
데이터 압축, 차원의 저주(curse of dimensionality) 예방, 특성 추출 등 인코더 디코더가 들어감.

GAN 적대적 생성 신경망: 적대적 생성 신경망(Generative Adversarial Network) 위조지폐범과 경찰과의 게임 경찰(판별자), 위조지폐범(생성자) 
판별자를 먼저 학습 시키고 생성자를 학습시키는 과정 반복 
서로 경쟁적으로 모델을 발전시킬 수 있는 구조
GAN을 학습시키려면 판별자와 생성자의 파라미터를 번갈아 가며 업데이트 함 , 판별자의 파라미터를 업데이트 할 때는 생성자의 파라미터 고정, 생성자의 파라미터를 업데이트 할 때는 판별자의 파라미터 고정
에포크 수가 증가 할 수록 진짜 이미지와 유사한 결과가 출력됨
GAN 파생기술  사이클 GAN만 시험 나옴    CycleGAN 말과 얼룩말 사진 합성 


50% 정도만 알려줌? 나머지는 퍼셉트론 쪽과 CNN쪽 코드및 pdf에서 나올 듯  
50점은 중간고사랑 위 의 내용에서 나오고 나머지50점은 CNN, 퍼셉트론
rnn은 시험에 안나옴
